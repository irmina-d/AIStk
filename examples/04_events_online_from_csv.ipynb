{"cells": [{"cell_type": "markdown", "id": "c1ea54d9", "metadata": {}, "source": ["# 04 \u2014 Online Events from CSV\n", "Simulate a streaming input by chunking a CSV and yielding events."]}, {"cell_type": "code", "execution_count": null, "id": "f4c46ba2", "metadata": {}, "outputs": [], "source": ["import json, polars as pl\n", "from aistk.streaming.events_online import process_stream"]}, {"cell_type": "code", "execution_count": null, "id": "97d7e602", "metadata": {}, "outputs": [], "source": ["path = 'data/ais/2024.csv'\n", "chunk = 20000\n", "lf = pl.scan_csv(path, has_header=True, infer_schema_length=0, ignore_errors=True, try_parse_dates=True)\n", "offset = 0\n", "while True:\n", "    df = lf.slice(offset, chunk).collect(engine=\"streaming\")\n", "    if df.height == 0:\n", "        break\n", "    cols = [c for c in ['MMSI','ts','LAT','LON','COG','SOG','Draft'] if c in df.columns]\n", "    recs = (dict(zip(cols, row)) for row in df.select(cols).iter_rows())\n", "    for ev in process_stream(recs, stop_min=10):\n", "        print(json.dumps(ev))\n", "    offset += chunk"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}