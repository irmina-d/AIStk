{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567e50d6",
   "metadata": {},
   "source": [
    "# 00 — End-to-End AIS Demo (CSV → Stats → Events → Map → Streaming)\n",
    "\n",
    "This notebook shows a **complete workflow** using the `aistk` toolkit:\n",
    "\n",
    "1. **Configure paths** to your AIS CSV file(s)\n",
    "2. **Load & filter** with `AISDataset`\n",
    "3. **Compute statistics** (eager and streaming-friendly)\n",
    "4. **Detect events**\n",
    "5. **Generate a quick map preview**\n",
    "6. **Simulate online streaming from CSV** and emit events\n",
    "\n",
    "> Works with a single CSV or a folder pattern like `data/ais/*.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ff39e",
   "metadata": {},
   "source": [
    "## 1) Prerequisites\n",
    "\n",
    "Make sure you have the package and optional extras installed.\n",
    "\n",
    "```bash\n",
    "pip install aistk polars folium shapely dask[complete] pyspark\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf385a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Configure data paths and parameters\n",
    "CSV_ROOT = 'data/ais'           # directory with CSV(s) OR path to a single CSV\n",
    "CSV_PATTERN = '*.csv'           # e.g. '*.csv' or '2024.csv'\n",
    "DATE_FROM = '2024-01-01'\n",
    "DATE_TO   = '2024-02-01'\n",
    "MMSI_LIST = [244660000]         # set to [] or None to include all\n",
    "\n",
    "OUT_PARQUET = 'out/demo_data.parquet'\n",
    "OUT_STATS   = 'out/demo_stats.parquet'\n",
    "OUT_EVENTS  = 'out/demo_events.parquet'\n",
    "OUT_MAP     = 'out/demo_map.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622d425",
   "metadata": {},
   "source": [
    "## 3) Load & Filter (AISDataset)\n",
    "\n",
    "We use the high-level dataset wrapper which builds a **Polars LazyFrame** under the hood and materializes on `collect()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistk.core import AISDataset\n",
    "import polars as pl\n",
    "\n",
    "# Build pipeline\n",
    "ds = AISDataset(CSV_ROOT, pattern=CSV_PATTERN)\n",
    "if MMSI_LIST:\n",
    "    ds = ds.filter(mmsi=MMSI_LIST)\n",
    "\n",
    "ds = ds.between(DATE_FROM, DATE_TO)\n",
    "\n",
    "df = ds.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5650d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rows:', df.height); print('Columns:', df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff683006",
   "metadata": {},
   "source": [
    "## 4) Save filtered subset (optional)\n",
    "\n",
    "This writes the collected frame to a single Parquet file for faster re-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.write_parquet(OUT_PARQUET)\n",
    "OUT_PARQUET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a8b55",
   "metadata": {},
   "source": [
    "## 5) Stats (eager Polars DataFrame)\n",
    "\n",
    "Compute per-MMSI metrics using the eager path (`compute_stats_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistk.stats import compute_stats_df\n",
    "stats_df = compute_stats_df(df, level='mmsi')\n",
    "stats_df.sort('distance_km', descending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51750698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist stats\n",
    "stats_df.write_parquet(OUT_STATS)\n",
    "OUT_STATS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d344d150",
   "metadata": {},
   "source": [
    "## 6) Stats (streaming-friendly with Polars Lazy)\n",
    "\n",
    "Same metrics computed as **expressions** on a `LazyFrame`. Good for very large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistk.stats_streaming import compute_stats_lazy\n",
    "lf = AISDataset(CSV_ROOT, pattern=CSV_PATTERN)._build()\n",
    "if MMSI_LIST:\n",
    "    lf = lf.filter(pl.col('MMSI').is_in(MMSI_LIST))\n",
    "lf = lf.filter((pl.col('ts') >= pl.lit(DATE_FROM)) & (pl.col('ts') < pl.lit(DATE_TO)))\n",
    "res_lazy = compute_stats_lazy(lf, level='mmsi').collect(streaming=True)\n",
    "res_lazy.sort('distance_km', descending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ec7b5",
   "metadata": {},
   "source": [
    "## 7) Event Detection (batch)\n",
    "\n",
    "Detect `sharp_turn`, `stop`, `gap`, and `draft_change` events on the collected DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb59235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aistk.events import detect_events_df\n",
    "ev = detect_events_df(df, turn_deg=30.0, stop_sog=0.5, stop_min=15, draft_jump_m=0.3)\n",
    "ev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist events\n",
    "ev.write_parquet(OUT_EVENTS)\n",
    "OUT_EVENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5fcc7",
   "metadata": {},
   "source": [
    "## 8) Quick Map Preview\n",
    "\n",
    "Render a Folium map for a selected MMSI (or all points if not provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_path = ds.plot_map(OUT_MAP, mmsi=MMSI_LIST[0] if MMSI_LIST else None)\n",
    "html_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4a4dc",
   "metadata": {},
   "source": [
    "## 9) Streaming Simulation from CSV\n",
    "\n",
    "Read the CSV in chunks, feed rows to the online detector, and print JSON events as they occur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from aistk.streaming.events_online import process_stream\n",
    "\n",
    "# Re-scan the CSV lazily for chunked reading\n",
    "lf_stream = pl.scan_csv(f\"{CSV_ROOT}/{CSV_PATTERN}\", has_header=True, infer_schema_length=0, ignore_errors=True, try_parse_dates=True)\n",
    "if MMSI_LIST and 'MMSI' in lf_stream.columns:\n",
    "    lf_stream = lf_stream.filter(pl.col('MMSI').is_in(MMSI_LIST))\n",
    "\n",
    "chunk_size = 20_000\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "    chunk = lf_stream.slice(offset, chunk_size).collect(streaming=True)\n",
    "    if chunk.height == 0:\n",
    "        break\n",
    "    cols = [c for c in ['MMSI','ts','LAT','LON','COG','SOG','Draft'] if c in chunk.columns]\n",
    "    recs = (dict(zip(cols, row)) for row in chunk.select(cols).iter_rows())\n",
    "    for event in process_stream(recs, stop_min=10):\n",
    "        print(json.dumps(event))\n",
    "    offset += chunk_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accdc90e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (Optional) CLI inside the notebook\n",
    "If you have the console entry `aistk` installed, you can run commands directly from notebook cells:\n",
    "\n",
    "```bash\n",
    "!aistk scan data/ais --from 2024-01-01 --to 2024-02-01 --to-parquet out/data.parquet\n",
    "!aistk stats data/ais --engine polars-stream --out out/stats.parquet\n",
    "!aistk events data/ais --out out/events.csv\n",
    "!aistk stream-csv data/ais/2024.csv --chunk-size 5000\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
